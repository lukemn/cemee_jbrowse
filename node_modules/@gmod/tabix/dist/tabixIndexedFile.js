'use strict';var _regenerator = require('babel-runtime/regenerator');var _regenerator2 = _interopRequireDefault(_regenerator);var _asyncToGenerator2 = require('babel-runtime/helpers/asyncToGenerator');var _asyncToGenerator3 = _interopRequireDefault(_asyncToGenerator2);var _classCallCheck2 = require('babel-runtime/helpers/classCallCheck');var _classCallCheck3 = _interopRequireDefault(_classCallCheck2);var _createClass2 = require('babel-runtime/helpers/createClass');var _createClass3 = _interopRequireDefault(_createClass2);var _promise = require('babel-runtime/core-js/promise');var _promise2 = _interopRequireDefault(_promise);function _interopRequireDefault(obj) {return obj && obj.__esModule ? obj : { default: obj };}var _require = require('./unzip'),unzip = _require.unzip,unzipChunk = _require.unzipChunk;
var LRU = require('lru-cache');

var LocalFile = require('./localFile');
var TBI = require('./tbi');
var CSI = require('./csi');

function timeout(time) {
  return new _promise2.default(function (resolve) {
    setTimeout(resolve, time);
  });
}var

TabixIndexedFile = function () {
  /**
                                 * @param {object} args
                                 * @param {string} [args.path]
                                 * @param {filehandle} [args.filehandle]
                                 * @param {string} [args.tbiPath]
                                 * @param {filehandle} [args.tbiFilehandle]
                                 * @param {string} [args.csiPath]
                                 * @param {filehandle} [args.csiFilehandle]
                                 * @param {number} [args.chunkSizeLimit] maximum number of bytes to fetch in a single `getLines` call.
                                 * default 2MiB
                                 * @param {number} [args.yieldLimit] maximum number of lines to parse without yielding.
                                 * this avoids having a large read prevent any other work getting done on the thread.  default 300 lines.
                                 * @param {function} [args.renameRefSeqs] optional function with sig `string => string` to transform
                                 * reference sequence names for the purpose of indexing and querying. note that the data that is returned is
                                 * not altered, just the names of the reference sequences that are used for querying.
                                 * @param {number} [args.chunkCacheSize] maximum size in bytes of the chunk cache. default 5MB
                                 * @param {number} [args.blockCacheSize] maximum size in bytes of the block cache. default 5MB
                                 */
  function TabixIndexedFile(_ref)











  {var path = _ref.path,filehandle = _ref.filehandle,tbiPath = _ref.tbiPath,tbiFilehandle = _ref.tbiFilehandle,csiPath = _ref.csiPath,csiFilehandle = _ref.csiFilehandle,_ref$chunkSizeLimit = _ref.chunkSizeLimit,chunkSizeLimit = _ref$chunkSizeLimit === undefined ? 2000000 : _ref$chunkSizeLimit,_ref$yieldLimit = _ref.yieldLimit,yieldLimit = _ref$yieldLimit === undefined ? 300 : _ref$yieldLimit,_ref$renameRefSeqs = _ref.renameRefSeqs,renameRefSeqs = _ref$renameRefSeqs === undefined ? function (n) {return n;} : _ref$renameRefSeqs,_ref$chunkCacheSize = _ref.chunkCacheSize,chunkCacheSize = _ref$chunkCacheSize === undefined ? 5 * Math.pow(2, 20) : _ref$chunkCacheSize,_ref$blockCacheSize = _ref.blockCacheSize,blockCacheSize = _ref$blockCacheSize === undefined ? 5 * Math.pow(2, 20) : _ref$blockCacheSize;(0, _classCallCheck3.default)(this, TabixIndexedFile);
    if (filehandle) this.filehandle = filehandle;else
    if (path) this.filehandle = new LocalFile(path);else
    throw new TypeError('must provide either filehandle or path');

    if (tbiFilehandle)
    this.index = new TBI({ filehandle: tbiFilehandle, renameRefSeqs: renameRefSeqs });else
    if (csiFilehandle)
    this.index = new CSI({ filehandle: csiFilehandle, renameRefSeqs: renameRefSeqs });else
    if (tbiPath)
    this.index = new TBI({
      filehandle: new LocalFile(tbiPath),
      renameRefSeqs: renameRefSeqs });else

    if (csiPath)
    this.index = new CSI({
      filehandle: new LocalFile(csiPath),
      renameRefSeqs: renameRefSeqs });else

    if (path) {
      this.index = new TBI({ filehandle: new LocalFile(path + '.tbi') });
    } else {
      throw new TypeError(
      'must provide one of tbiFilehandle, tbiPath, csiFilehandle, or csiPath');

    }

    this.chunkSizeLimit = chunkSizeLimit;
    this.yieldLimit = yieldLimit;
    this.renameRefSeqCallback = renameRefSeqs;
    this.chunkCache = LRU({
      max: Math.floor(chunkCacheSize / (1 << 16)),
      length: function length() {return 1;} });

    this.blockCache = LRU({ max: Math.floor(blockCacheSize / (1 << 16)) });
  }

  /**
     * @param {string} refName name of the reference sequence
     * @param {number} start start of the region (in 0-based half-open coordinates)
     * @param {number} end end of the region (in 0-based half-open coordinates)
     * @param {function} lineCallback callback called for each line in the region, called as (line, fileOffset)
     * @returns {Promise} resolved when the whole read is finished, rejected on error
     */(0, _createClass3.default)(TabixIndexedFile, [{ key: 'getLines', value: function () {var _ref2 = (0, _asyncToGenerator3.default)( /*#__PURE__*/_regenerator2.default.mark(function _callee(
      refName, start, end, lineCallback) {var chunks, metadata, i, size, linesSinceLastYield, chunkNum, previousStartCoordinate, lines, currentLineStart, _i, line, fileOffset, _checkLine, startCoordinate, overlaps;return _regenerator2.default.wrap(function _callee$(_context) {while (1) {switch (_context.prev = _context.next) {case 0:if (!(
                refName === undefined)) {_context.next = 2;break;}throw (
                  new TypeError('must provide a reference sequence name'));case 2:if (
                start <= end) {_context.next = 4;break;}throw (
                  new TypeError(
                  'invalid start and end coordinates. must be provided, and start must be less than or equal to end'));case 4:if (

                lineCallback) {_context.next = 6;break;}throw new TypeError('line callback must be provided');case 6:_context.next = 8;return (

                  this.index.blocksForRange(refName, start, end));case 8:chunks = _context.sent;_context.next = 11;return (
                  this.index.getMetadata());case 11:metadata = _context.sent;
                metadata.maxColumn = Math.max(
                metadata.columnNumbers.ref || 0,
                metadata.columnNumbers.start || 0,
                metadata.columnNumbers.end || 0);


                // check the chunks for any that are over the size limit.  if
                // any are, don't fetch any of them
                i = 0;case 14:if (!(i < chunks.length)) {_context.next = 21;break;}
                size = chunks[i].fetchedSize();if (!(
                size > this.chunkSizeLimit)) {_context.next = 18;break;}throw (
                  new Error('Too much data. Chunk size ' +
                  size.toLocaleString() + ' bytes exceeds chunkSizeLimit of ' + this.chunkSizeLimit.toLocaleString() + '.'));case 18:i += 1;_context.next = 14;break;case 21:




                // now go through each chunk and parse and filter the lines out of it
                linesSinceLastYield = 0;
                chunkNum = 0;case 23:if (!(chunkNum < chunks.length)) {_context.next = 55;break;}
                previousStartCoordinate = void 0;_context.next = 27;return (
                  this.readChunk(chunks[chunkNum]));case 27:lines = _context.sent;

                currentLineStart = 0;
                _i = 0;case 30:if (!(_i < lines.length)) {_context.next = 52;break;}
                line = lines[_i];
                fileOffset =
                chunks[chunkNum].minv.blockPosition * Math.pow(2, 16) + currentLineStart;
                // filter the line for whether it is within the requested range
                _checkLine = this.checkLine(
                metadata,
                refName,
                start,
                end,
                line), startCoordinate = _checkLine.startCoordinate, overlaps = _checkLine.overlaps;


                // do a small check just to make sure that the lines are really sorted by start coordinate
                if (!(previousStartCoordinate > startCoordinate)) {_context.next = 36;break;}throw (
                  new Error('Lines not sorted by start coordinate (' +
                  previousStartCoordinate + ' > ' + startCoordinate + '), this file is not usable with Tabix.'));case 36:

                previousStartCoordinate = startCoordinate;if (!

                overlaps) {_context.next = 41;break;}
                lineCallback(line, fileOffset);_context.next = 43;break;case 41:if (!(
                startCoordinate >= end)) {_context.next = 43;break;}return _context.abrupt('return');case 43:






                currentLineStart += line.length;

                // yield if we have emitted beyond the yield limit
                linesSinceLastYield += 1;if (!(
                linesSinceLastYield >= this.yieldLimit)) {_context.next = 49;break;}_context.next = 48;return (
                  timeout(1));case 48:
                linesSinceLastYield = 0;case 49:_i += 1;_context.next = 30;break;case 52:chunkNum += 1;_context.next = 23;break;case 55:case 'end':return _context.stop();}}}, _callee, this);}));function getLines(_x, _x2, _x3, _x4) {return _ref2.apply(this, arguments);}return getLines;}() }, { key: 'getMetadata', value: function () {var _ref3 = (0, _asyncToGenerator3.default)( /*#__PURE__*/_regenerator2.default.mark(function _callee2() {return _regenerator2.default.wrap(function _callee2$(_context2) {while (1) {switch (_context2.prev = _context2.next) {case 0:return _context2.abrupt('return',






                this.index.getMetadata());case 1:case 'end':return _context2.stop();}}}, _callee2, this);}));function getMetadata() {return _ref3.apply(this, arguments);}return getMetadata;}()


    /**
                                                                                                                                                                                                  * get a buffer containing the "header" region of
                                                                                                                                                                                                  * the file, which are the bytes up to the first
                                                                                                                                                                                                  * non-meta line
                                                                                                                                                                                                  *
                                                                                                                                                                                                  * @returns {Promise} for a buffer
                                                                                                                                                                                                  */ }, { key: 'getHeaderBuffer', value: function () {var _ref4 = (0, _asyncToGenerator3.default)( /*#__PURE__*/_regenerator2.default.mark(function _callee3() {var _ref5, firstDataLine, metaChar, maxBlockSize, maxFetch, bytes, lastNewline, newlineByte, metaByte, i;return _regenerator2.default.wrap(function _callee3$(_context3) {while (1) {switch (_context3.prev = _context3.next) {case 0:_context3.next = 2;return (

                  this.getMetadata());case 2:_ref5 = _context3.sent;firstDataLine = _ref5.firstDataLine;metaChar = _ref5.metaChar;maxBlockSize = _ref5.maxBlockSize;
                maxFetch =
                firstDataLine && firstDataLine.blockPosition ?
                firstDataLine.blockPosition + maxBlockSize :
                maxBlockSize;
                // TODO: what if we don't have a firstDataLine, and the header
                // actually takes up more than one block? this case is not covered here
                _context3.next = 9;return (
                  this._readRegion(0, maxFetch));case 9:bytes = _context3.sent;_context3.prev = 10;

                bytes = unzip(bytes);_context3.next = 17;break;case 14:_context3.prev = 14;_context3.t0 = _context3['catch'](10);throw (

                  new Error('error decompressing block ' +
                  _context3.t0.code + ' at 0 (length ' + maxFetch + ')', _context3.t0));case 17:if (!





                metaChar) {_context3.next = 32;break;}
                // trim backward from the end
                lastNewline = -1;
                newlineByte = '\n'.charCodeAt(0);
                metaByte = metaChar.charCodeAt(0);
                i = 0;case 22:if (!(i < bytes.length)) {_context3.next = 31;break;}if (!(
                bytes[i] === newlineByte)) {_context3.next = 28;break;}
                lastNewline = i;
                i += 1;if (!(
                bytes[i] !== metaByte)) {_context3.next = 28;break;}return _context3.abrupt('break', 31);case 28:i += 1;_context3.next = 22;break;case 31:


                bytes = bytes.slice(0, lastNewline + 1);case 32:return _context3.abrupt('return',

                bytes);case 33:case 'end':return _context3.stop();}}}, _callee3, this, [[10, 14]]);}));function getHeaderBuffer() {return _ref4.apply(this, arguments);}return getHeaderBuffer;}()


    /**
                                                                                                                                                                                                    * get a string containing the "header" region of the
                                                                                                                                                                                                    * file, is the portion up to the first non-meta line
                                                                                                                                                                                                    *
                                                                                                                                                                                                    * @returns {Promise} for a string
                                                                                                                                                                                                    */ }, { key: 'getHeader', value: function () {var _ref6 = (0, _asyncToGenerator3.default)( /*#__PURE__*/_regenerator2.default.mark(function _callee4() {var bytes;return _regenerator2.default.wrap(function _callee4$(_context4) {while (1) {switch (_context4.prev = _context4.next) {case 0:_context4.next = 2;return (

                  this.getHeaderBuffer());case 2:bytes = _context4.sent;return _context4.abrupt('return',
                bytes.toString('utf8'));case 4:case 'end':return _context4.stop();}}}, _callee4, this);}));function getHeader() {return _ref6.apply(this, arguments);}return getHeader;}()


    /**
                                                                                                                                                                                            * get an array of reference sequence names, in the order in which
                                                                                                                                                                                            * they occur in the file.
                                                                                                                                                                                            *
                                                                                                                                                                                            * reference sequence renaming is not applied to these names.
                                                                                                                                                                                            *
                                                                                                                                                                                            * @returns {Promise} for an array of string sequence names
                                                                                                                                                                                            */ }, { key: 'getReferenceSequenceNames', value: function () {var _ref7 = (0, _asyncToGenerator3.default)( /*#__PURE__*/_regenerator2.default.mark(function _callee5() {var metadata;return _regenerator2.default.wrap(function _callee5$(_context5) {while (1) {switch (_context5.prev = _context5.next) {case 0:_context5.next = 2;return (

                  this.getMetadata());case 2:metadata = _context5.sent;return _context5.abrupt('return',
                metadata.refIdToName);case 4:case 'end':return _context5.stop();}}}, _callee5, this);}));function getReferenceSequenceNames() {return _ref7.apply(this, arguments);}return getReferenceSequenceNames;}() }, { key: 'renameRefSeq', value: function renameRefSeq(


    refName) {
      if (this._renameRefSeqCache && this._renameRefSeqCache.from === refName)
      return this._renameRefSeqCache.to;

      var renamed = this.renameRefSeqCallback(refName);
      this._renameRefSeqCache = { from: refName, to: renamed };
      return renamed;
    }

    /**
       * @param {object} metadata metadata object from the parsed index,
       * containing columnNumbers, metaChar, and maxColumn
       * @param {string} regionRefName
       * @param {number} regionStart region start coordinate (0-based-half-open)
       * @param {number} regionEnd region end coordinate (0-based-half-open)
       * @param {array[string]} line
       * @returns {object} like `{startCoordinate, overlaps}`. overlaps is boolean,
       * true if line is a data line that overlaps the given region
       */ }, { key: 'checkLine', value: function checkLine(_ref8,


    regionRefName,
    regionStart,
    regionEnd,
    line)
    {var columnNumbers = _ref8.columnNumbers,metaChar = _ref8.metaChar,maxColumn = _ref8.maxColumn,coordinateType = _ref8.coordinateType;
      // skip meta lines
      if (line.charAt(0) === metaChar) return { overlaps: false

        // check ref/start/end using column metadata from index
      };var ref = columnNumbers.ref,start = columnNumbers.start,end = columnNumbers.end;
      if (!ref) ref = 0;
      if (!start) start = 0;
      if (!end) end = 0;

      // this code is kind of complex, but it is fairly fast.
      // basically, we want to avoid doing a split, because if the lines are really long
      // that could lead to us allocating a bunch of extra memory, which is slow

      var currentColumnNumber = 1; // cols are numbered starting at 1 in the index metadata
      var currentColumnStart = 0;
      var startCoordinate = void 0;
      for (var i = 0; i < line.length; i += 1) {
        if (line[i] === '\t') {
          if (currentColumnNumber === ref) {
            var refName = line.slice(currentColumnStart, i);
            refName = this.renameRefSeq(refName);
            if (refName !== regionRefName) return { overlaps: false };
          } else if (currentColumnNumber === start) {
            startCoordinate = parseInt(line.slice(currentColumnStart, i), 10);
            // we convert to 0-based-half-open
            if (coordinateType === '1-based-closed') startCoordinate -= 1;
            if (startCoordinate >= regionEnd) return { overlaps: false };
            if (end === 0) {
              // if we have no end, we assume the feature is 1 bp long
              if (startCoordinate + 1 <= regionStart) return { overlaps: false };
            }
          } else if (currentColumnNumber === end) {
            // this will never match if there is no end column
            var endCoordinate = parseInt(line.slice(currentColumnStart, i), 10);
            if (endCoordinate <= regionStart) return { overlaps: false };
          }
          currentColumnStart = i + 1;
          currentColumnNumber += 1;
          if (currentColumnNumber > maxColumn) break;
        }
      }
      return { startCoordinate: startCoordinate, overlaps: true };
    }

    /**
       * return the approximate number of data lines in the given reference sequence
       * @param {string} refSeq reference sequence name
       * @returns {Promise} for number of data lines present on that reference sequence
       */ }, { key: 'lineCount', value: function () {var _ref9 = (0, _asyncToGenerator3.default)( /*#__PURE__*/_regenerator2.default.mark(function _callee6(
      refSeq) {return _regenerator2.default.wrap(function _callee6$(_context6) {while (1) {switch (_context6.prev = _context6.next) {case 0:return _context6.abrupt('return',
                this.index.lineCount(refSeq));case 1:case 'end':return _context6.stop();}}}, _callee6, this);}));function lineCount(_x5) {return _ref9.apply(this, arguments);}return lineCount;}() }, { key: '_cacheWith', value: function _cacheWith(


    cache, cacheKey, fillCallback) {
      var cachedPromise = cache.get(cacheKey);
      if (cachedPromise) return cachedPromise;

      var freshPromise = fillCallback();
      cache.set(cacheKey, freshPromise);
      return freshPromise;
    } }, { key: '_readRegion', value: function () {var _ref10 = (0, _asyncToGenerator3.default)( /*#__PURE__*/_regenerator2.default.mark(function _callee7(

      position, compressedSize) {var _ref11, fileSize, compressedData;return _regenerator2.default.wrap(function _callee7$(_context7) {while (1) {switch (_context7.prev = _context7.next) {case 0:_context7.next = 2;return (

                  this.filehandle.stat());case 2:_ref11 = _context7.sent;fileSize = _ref11.size;
                if (position + compressedSize > fileSize)
                compressedSize = fileSize - position;

                compressedData = Buffer.alloc(compressedSize);

                /* const bytesRead = */_context7.next = 8;return this.filehandle.read(
                compressedData,
                0,
                compressedSize,
                position);case 8:return _context7.abrupt('return',


                compressedData);case 9:case 'end':return _context7.stop();}}}, _callee7, this);}));function _readRegion(_x6, _x7) {return _ref10.apply(this, arguments);}return _readRegion;}()


    /**
                                                                                                                                                                                                 * read and uncompress the data in a chunk (composed of one or more
                                                                                                                                                                                                 * contiguous bgzip blocks) of the file
                                                                                                                                                                                                 * @param {Chunk} chunk
                                                                                                                                                                                                 * @returns {Promise} for a string chunk of the file
                                                                                                                                                                                                 */ }, { key: 'readChunk', value: function readChunk(
    chunk) {var _this = this;
      return this._cacheWith(this.chunkCache, chunk.toString(), (0, _asyncToGenerator3.default)( /*#__PURE__*/_regenerator2.default.mark(function _callee8() {var compressedData, uncompressed, lines;return _regenerator2.default.wrap(function _callee8$(_context8) {while (1) {switch (_context8.prev = _context8.next) {case 0:_context8.next = 2;return (



                  _this._readRegion(
                  chunk.minv.blockPosition,
                  chunk.fetchedSize()));case 2:compressedData = _context8.sent;

                uncompressed = void 0;_context8.prev = 4;

                uncompressed = unzipChunk(compressedData, chunk);_context8.next = 11;break;case 8:_context8.prev = 8;_context8.t0 = _context8['catch'](4);throw (

                  new Error('error decompressing chunk ' + chunk.toString()));case 11:


                lines = uncompressed.toString('utf8').split('\n');

                // remove the last line, since it will be either empty or partial
                lines.pop();return _context8.abrupt('return',

                lines);case 14:case 'end':return _context8.stop();}}}, _callee8, _this, [[4, 8]]);})));

    } }]);return TabixIndexedFile;}();


module.exports = TabixIndexedFile;