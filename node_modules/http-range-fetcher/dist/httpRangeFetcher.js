'use strict';var _assign = require('babel-runtime/core-js/object/assign');var _assign2 = _interopRequireDefault(_assign);var _isNan = require('babel-runtime/core-js/number/is-nan');var _isNan2 = _interopRequireDefault(_isNan);var _toConsumableArray2 = require('babel-runtime/helpers/toConsumableArray');var _toConsumableArray3 = _interopRequireDefault(_toConsumableArray2);var _regenerator = require('babel-runtime/regenerator');var _regenerator2 = _interopRequireDefault(_regenerator);var _promise = require('babel-runtime/core-js/promise');var _promise2 = _interopRequireDefault(_promise);var _asyncToGenerator2 = require('babel-runtime/helpers/asyncToGenerator');var _asyncToGenerator3 = _interopRequireDefault(_asyncToGenerator2);var _classCallCheck2 = require('babel-runtime/helpers/classCallCheck');var _classCallCheck3 = _interopRequireDefault(_classCallCheck2);var _createClass2 = require('babel-runtime/helpers/createClass');var _createClass3 = _interopRequireDefault(_createClass2);function _interopRequireDefault(obj) {return obj && obj.__esModule ? obj : { default: obj };}var LRU = require('lru-cache');var _require =

require('./cacheSemantics'),CacheSemantics = _require.CacheSemantics;
var AggregatingFetcher = require('./aggregatingFetcher');

var crossFetchBinaryRange = require('./crossFetchBinaryRange');

// TODO: fire events when a remote file is detected as having been changed

/**
 * smart cache that fetches chunks of remote files.
 * caches chunks in an LRU cache, and aggregates upstream fetches
 */var
HttpRangeFetcher = function () {
  /**
                                 * @param {object} args the arguments object
                                 * @param {number} [args.fetch] callback with signature `(key, start, end) => Promise({ headers, buffer })`
                                 * @param {number} [args.size] size in bytes of cache to keep
                                 * @param {number} [args.chunkSize] size in bytes of cached chunks
                                 * @param {number} [args.aggregationTime] time in ms over which to pool requests before dispatching them
                                 * @param {number} [args.minimumTTL] time in ms a non-cacheable response will be cached
                                 * @param {number} [args.maxFetchSize] maximum size of an aggregated request
                                 * @param {number} [args.maxExtraFetch] max number of additional bytes to fetch when aggregating requests
                                 * that don't actually overlap
                                 */
  function HttpRangeFetcher(_ref)







  {var _ref$fetch = _ref.fetch,fetch = _ref$fetch === undefined ? crossFetchBinaryRange : _ref$fetch,_ref$size = _ref.size,size = _ref$size === undefined ? 10000000 : _ref$size,_ref$chunkSize = _ref.chunkSize,chunkSize = _ref$chunkSize === undefined ? 32768 : _ref$chunkSize,_ref$aggregationTime = _ref.aggregationTime,aggregationTime = _ref$aggregationTime === undefined ? 100 : _ref$aggregationTime,_ref$minimumTTL = _ref.minimumTTL,minimumTTL = _ref$minimumTTL === undefined ? 1000 : _ref$minimumTTL,_ref$maxFetchSize = _ref.maxFetchSize,maxFetchSize = _ref$maxFetchSize === undefined ? chunkSize * 4 : _ref$maxFetchSize,_ref$maxExtraFetch = _ref.maxExtraFetch,maxExtraFetch = _ref$maxExtraFetch === undefined ? chunkSize : _ref$maxExtraFetch;(0, _classCallCheck3.default)(this, HttpRangeFetcher);
    this.aggregator = new AggregatingFetcher({
      fetch: fetch,
      frequency: aggregationTime,
      maxFetchSize: maxFetchSize,
      maxExtraSize: maxExtraFetch });

    this.chunkSize = chunkSize;
    this.chunkCache = LRU({ max: Math.floor(size / chunkSize) });
    this.cacheSemantics = new CacheSemantics({ minimumTTL: minimumTTL });
    this.stats = LRU({ max: 20 });
  }

  /**
     * Fetch a range of a remote resource.
     * @param {string} key the resource's unique identifier, this would usually be a URL.
     * This is passed along to the fetch callback.
     * @param {number} [position] offset in the file at which to start fetching
     * @param {number} [length] number of bytes to fetch, defaults to the remainder of the file
     */(0, _createClass3.default)(HttpRangeFetcher, [{ key: 'getRange', value: function () {var _ref2 = (0, _asyncToGenerator3.default)( /*#__PURE__*/_regenerator2.default.mark(function _callee(
      key) {var _this = this;var position = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;var length = arguments[2];var stat, firstChunk, lastChunk, fetches, _loop, chunk, chunkResponses, chunksOffset;return _regenerator2.default.wrap(function _callee$(_context) {while (1) {switch (_context.prev = _context.next) {case 0:if (!(
                length === undefined)) {_context.next = 7;break;}_context.next = 3;return (
                  this.stat(key));case 3:stat = _context.sent;if (!(
                stat.size === undefined)) {_context.next = 6;break;}throw (
                  new Error('length not specified, and could not determine size of the remote file'));case 6:


                length = stat.size - position;case 7:


                // calculate the list of chunks involved in this fetch
                firstChunk = Math.floor(position / this.chunkSize);
                lastChunk = Math.floor((position + length - 1) / this.chunkSize);

                // fetch them all as necessary
                fetches = new Array(lastChunk - firstChunk + 1);_loop = function _loop(
                chunk) {
                  fetches[chunk - firstChunk] = _this._getChunk(key, chunk).then(
                  function (response) {return (
                      response && {
                        headers: response.headers,
                        buffer: response.buffer,
                        chunkNumber: chunk });});};for (chunk = firstChunk; chunk <= lastChunk; chunk += 1) {_loop(chunk);


                }

                // return a "composite buffer" that lets the array of chunks be accessed like a flat buffer
                _context.next = 14;return _promise2.default.all(fetches);case 14:chunkResponses = _context.sent;
                chunkResponses = chunkResponses.filter(function (r) {return !!r;}); // filter out any undefined (out of range) responses
                if (chunkResponses.length) {_context.next = 18;break;}return _context.abrupt('return',
                { headers: {}, buffer: Buffer.allocUnsafe(0) });case 18:

                chunksOffset =
                position - chunkResponses[0].chunkNumber * this.chunkSize;return _context.abrupt('return',
                {
                  headers: this._makeHeaders(
                  chunkResponses[0].headers,
                  position,
                  position + length - 1),

                  buffer: this._makeBuffer(chunkResponses, chunksOffset, length) });case 20:case 'end':return _context.stop();}}}, _callee, this);}));function getRange(_x2) {return _ref2.apply(this, arguments);}return getRange;}() }, { key: '_makeBuffer', value: function _makeBuffer(



    chunkResponses, chunksOffset, length) {
      if (chunkResponses.length === 1) {
        return chunkResponses[0].buffer.slice(chunksOffset, chunksOffset + length);
      } else if (chunkResponses.length === 0) {
        return Buffer.allocUnsafe(0);
      }
      // 2 or more buffers
      var buffers = chunkResponses.map(function (r) {return r.buffer;});
      var first = buffers.shift().slice(chunksOffset);
      var last = buffers.pop();
      var trimEnd =
      first.length +
      buffers.reduce(function (sum, buf) {return sum + buf.length;}, 0) +
      last.length -
      length;
      if (trimEnd < 0) {
        trimEnd = 0;
      }
      last = last.slice(0, last.length - trimEnd);
      return Buffer.concat([first].concat((0, _toConsumableArray3.default)(buffers), [last]));
    }

    /**
       * Fetches the first few bytes of the remote file (if necessary) and uses
       * the returned headers to populate a `fs`-like stat object.
       *
       * Currently, this attempts to set `size`, `mtime`, and `mtimeMs`, if
       * the information is available from HTTP headers.
       *
       * @param {string} key
       * @returns {Promise} for a stats object
       */ }, { key: 'stat', value: function () {var _ref3 = (0, _asyncToGenerator3.default)( /*#__PURE__*/_regenerator2.default.mark(function _callee2(
      key) {var stat;return _regenerator2.default.wrap(function _callee2$(_context2) {while (1) {switch (_context2.prev = _context2.next) {case 0:
                stat = this.stats.get(key);if (
                stat) {_context2.next = 7;break;}_context2.next = 4;return (
                  this._getChunk(key, 0));case 4:
                stat = this.stats.get(key);if (
                stat) {_context2.next = 7;break;}throw new Error('failed to retrieve file size for ' + key);case 7:return _context2.abrupt('return',

                stat);case 8:case 'end':return _context2.stop();}}}, _callee2, this);}));function stat(_x3) {return _ref3.apply(this, arguments);}return stat;}() }, { key: '_headersToStats', value: function _headersToStats(


    chunkResponse) {var
      headers = chunkResponse.headers;
      var stat = {};
      if (headers['content-range']) {
        var match = headers['content-range'].match(/\d+-\d+\/(\d+)/);
        if (match) {
          stat.size = parseInt(match[1], 10);
          if ((0, _isNan2.default)(stat.size)) delete stat.size;
        }
      }
      if (headers['last-modified']) {
        stat.mtime = new Date(headers['last-modified']);
        if (stat.mtime.toString() === 'Invalid Date') delete stat.mtime;
        if (stat.mtime) {
          stat.mtimeMs = stat.mtime.getTime();
        }
      }
      return stat;
    } }, { key: '_makeHeaders', value: function _makeHeaders(

    originalHeaders, newStart, newEnd) {
      var newHeaders = (0, _assign2.default)({}, originalHeaders || {});
      newHeaders['content-length'] = newEnd - newStart;
      var oldContentRange = newHeaders['content-range'] || '';
      var match = oldContentRange.match(/\d+-\d+\/(\d+)/);
      if (match) {
        newHeaders['content-range'] = newStart + '-' + (newEnd - 1) + '/' + match[1];
        newHeaders['x-resource-length'] = match[1];
      }
      return newHeaders;
    } }, { key: '_getChunk', value: function () {var _ref4 = (0, _asyncToGenerator3.default)( /*#__PURE__*/_regenerator2.default.mark(function _callee3(

      key, chunkNumber) {var _this2 = this;var chunkKey, cachedPromise, chunk, fetchStart, fetchEnd, stat, freshPromise, freshChunk;return _regenerator2.default.wrap(function _callee3$(_context3) {while (1) {switch (_context3.prev = _context3.next) {case 0:
                chunkKey = key + '/' + chunkNumber;
                cachedPromise = this.chunkCache.get(chunkKey);if (!

                cachedPromise) {_context3.next = 10;break;}_context3.next = 5;return (
                  cachedPromise);case 5:chunk = _context3.sent;if (


                this.cacheSemantics.cachedChunkIsValid(chunk)) {_context3.next = 9;break;}
                this._uncacheIfSame(chunkKey, cachedPromise);return _context3.abrupt('return',
                this._getChunk(key, chunkNumber));case 9:return _context3.abrupt('return',

                chunk);case 10:


                fetchStart = chunkNumber * this.chunkSize;
                fetchEnd = fetchStart + this.chunkSize;

                // clamp the end of the fetch to the size if we have a cached size for the file
                stat = this.stats.get(key);if (!(
                stat && stat.size)) {_context3.next = 17;break;}if (!(
                fetchStart >= stat.size)) {_context3.next = 16;break;}return _context3.abrupt('return',
                undefined);case 16:

                if (fetchEnd >= stat.size) fetchEnd = stat.size;case 17:


                freshPromise = this.aggregator.fetch(key, fetchStart, fetchEnd);
                // if the request fails, remove its promise
                // from the cache and keep the error
                freshPromise.catch(function (err) {
                  _this2._uncacheIfSame(chunkKey, freshPromise);
                  throw err;
                });

                this.chunkCache.set(chunkKey, freshPromise);_context3.next = 22;return (

                  freshPromise);case 22:freshChunk = _context3.sent;

                // gather the stats for the file from the headers
                this.stats.set(key, this._headersToStats(freshChunk));

                // remove the promise from the cache
                // if it turns out not to be cacheable. this is
                // done after the fact because we want multiple requests
                // for the same chunk to reuse the same cached promise
                if (!this.cacheSemantics.chunkIsCacheable(freshChunk)) {
                  this._uncacheIfSame(key, freshPromise);
                }return _context3.abrupt('return',

                freshChunk);case 26:case 'end':return _context3.stop();}}}, _callee3, this);}));function _getChunk(_x4, _x5) {return _ref4.apply(this, arguments);}return _getChunk;}()


    // delete a promise from the cache if it is still in there.
    // need to check if it is still the same because it might
    // have been overwritten sometime while the promise was in flight
  }, { key: '_uncacheIfSame', value: function _uncacheIfSame(key, cachedPromise) {
      if (this.chunkCache.get(key) === cachedPromise) {
        this.chunkCache.del(key);
      }
    }

    /**
       * Throw away all cached data, resetting the cache.
       */ }, { key: 'reset', value: function reset()
    {
      this.stats.reset();
      this.chunkCache.reset();
    } }]);return HttpRangeFetcher;}();


module.exports = HttpRangeFetcher;